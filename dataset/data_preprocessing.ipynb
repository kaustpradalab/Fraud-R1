{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files have been combined into combined_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Folder containing the JSON files\n",
    "folder_path = \"./\"  # Update to your folder path\n",
    "output_file = \"combined_dataset.json\"\n",
    "\n",
    "# Initialize an empty list to store data from all JSON files\n",
    "combined_data = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):  # Process only JSON files\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            data = json.load(json_file)  # Load the content of the JSON file\n",
    "            # Check if the data is a list or a single object\n",
    "            if isinstance(data, list):\n",
    "                combined_data.extend(data)  # Append list data\n",
    "            else:\n",
    "                combined_data.append(data)  # Append single object\n",
    "\n",
    "# Reorder index (assign new unique IDs sequentially)\n",
    "for idx, item in enumerate(combined_data):\n",
    "    item['id'] = idx  # Reassign ID to be sequential starting from 0\n",
    "\n",
    "# Save the combined data to a single JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump(combined_data, out_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"All JSON files have been combined and reindexed into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data has been saved to Fraud24kRaw.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1987/2291331085.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = df.groupby('subcategory', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 加载 JSON 文件\n",
    "input_file = \"./original/combined_dataset.json\"  # 替换为你的 JSON 文件路径\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    combined_data = json.load(file)\n",
    "\n",
    "# 将数据加载到 Pandas DataFrame\n",
    "df = pd.DataFrame(combined_data)\n",
    "\n",
    "# 定义每个 subcategory 抽样的数量\n",
    "sample_size = 100\n",
    "\n",
    "# 按 'subcategory' 分组，然后从每组中随机抽取指定数量的样本\n",
    "sampled_data = df.groupby('subcategory', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size)))\n",
    "\n",
    "# 重置索引\n",
    "sampled_data = sampled_data.reset_index(drop=True)\n",
    "\n",
    "# 将抽取的数据保存到一个新的 JSON 文件\n",
    "output_file = \"Fraud24kRaw.json\"\n",
    "sampled_data.to_json(output_file, orient=\"records\", force_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Sampled data has been saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数据量: 1236\n",
      "\n",
      "每个 'subcategory' 的数量:\n",
      "subcategory\n",
      "acquaintances                                                       100\n",
      "e-commerce logistics and shopping                                   100\n",
      "fake job posting                                                    100\n",
      "marriage and dating                                                 100\n",
      "investment and financial management                                 100\n",
      "ssn                                                                 100\n",
      "reward                                                              100\n",
      "public security, prosecution, judiciary, and government agencies    100\n",
      "refund                                                              100\n",
      "support                                                             100\n",
      "commercial spam                                                      80\n",
      "fraud                                                                80\n",
      "phishing                                                             76\n",
      "Name: count, dtype: int64\n",
      "\n",
      "每个 'category' 的数量:\n",
      "category\n",
      "fraudulent service    500\n",
      "phishing              336\n",
      "impersonation         200\n",
      "fake job posting      100\n",
      "network friendship    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "每个 'language' 的数量:\n",
      "language\n",
      "English    736\n",
      "Chinese    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "每个 'data_type' 的数量:\n",
      "data_type\n",
      "dialogue      534\n",
      "message       366\n",
      "email         236\n",
      "dictionary    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 加载抽样后的 JSON 文件\n",
    "output_file = \"Fraud24kRaw.json\"  # 替换为保存的抽样 JSON 文件路径\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    sampled_data = json.load(file)\n",
    "\n",
    "# 将数据加载到 Pandas DataFrame\n",
    "df_sampled = pd.DataFrame(sampled_data)\n",
    "\n",
    "# 总数据量\n",
    "total_count = len(df_sampled)\n",
    "print(f\"总数据量: {total_count}\")\n",
    "\n",
    "# 按 'subcategory' 统计数量\n",
    "subcategory_counts = df_sampled['subcategory'].value_counts()\n",
    "print(\"\\n每个 'subcategory' 的数量:\")\n",
    "print(subcategory_counts)\n",
    "\n",
    "# 按 'category' 统计数量\n",
    "category_counts = df_sampled['category'].value_counts()\n",
    "print(\"\\n每个 'category' 的数量:\")\n",
    "print(category_counts)\n",
    "\n",
    "category_counts = df_sampled['language'].value_counts()\n",
    "print(\"\\n每个 'language' 的数量:\")\n",
    "print(category_counts)\n",
    "\n",
    "# 按 'data_type' 统计数量\n",
    "if 'data_type' in df_sampled.columns:\n",
    "    data_type_counts = df_sampled['data_type'].value_counts()\n",
    "    print(\"\\n每个 'data_type' 的数量:\")\n",
    "    print(data_type_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
